"""
SemiProcess MCP Server - ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ë¶„ì„ ë„êµ¬ ì§‘í•© (15ê°œ Tool)
"""

from typing import Any, Dict, List, Optional
import statistics

from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse, Response

app = FastAPI(title="SemiProcess MCP Server")

DISCLAIMER = """
> ğŸ“Œ **ë¶„ì„ ê¸°ì¤€ ì•ˆë‚´**
>
> ë³¸ ë¶„ì„ì€ ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤:
> - **ì…ë ¥ ë°ì´í„°**: ì‚¬ìš©ì ì œê³µ (ì •í™•ì„±ì€ ì‚¬ìš©ì ì±…ì„)
> - **ê³„ì‚° ë¡œì§**: ì‚°ì—… í‘œì¤€ ë°©ë²•ë¡ ì„ ì°¸ê³ (ISO/AIAG/FMEA/DOE ë“±)í•˜ë˜, ë‹¨ìˆœí™”ëœ ê³„ì‚°ì„ ì ìš©
> - **ê²°ê³¼ í™œìš©**: ì°¸ê³ ìš©ì´ë©°, ìµœì¢… ì˜ì‚¬ê²°ì • ì „ ì „ë¬¸ê°€ ê²€í†  ê¶Œì¥
>
> âš ï¸ ì‹¤ë¬´ ì ìš© ì‹œ ì‚¬ë‚´ í‘œì¤€, ì‹¤ì¸¡ ë°ì´í„°, ì „ë¬¸ê°€ ê²€ì¦ì„ ë°˜ë“œì‹œ ë³‘í–‰í•˜ì„¸ìš”.
"""


def _missing(required: List[str], provided: Dict[str, Any]) -> List[str]:
    return [k for k in required if provided.get(k) is None]


def _err_missing(missing: List[str]) -> str:
    items = "\n".join(f"- `{m}`" for m in missing)
    return f"{DISCLAIMER}\n\n## âš ï¸ ì…ë ¥ ì˜¤ë¥˜\ní•„ìˆ˜ ì…ë ¥ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.\n{items}"


def analyze_defect(
    defect_code: str,
    defect_description: str,
    process_step: str,
    equipment_id: str = None,
    wafer_id: str = None,
    known_causes: Optional[List[str]] = None,
    recent_changes: Optional[List[str]] = None,
) -> str:
    miss = _missing(["defect_code", "defect_description", "process_step"], locals())
    if miss:
        return _err_missing(miss)
    causes = "\n".join(f"- {c}" for c in (known_causes or [])) or "- (ì‚¬ìš©ì ì›ì¸ ë¯¸ì…ë ¥)"
    changes = "\n".join(f"- {c}" for c in (recent_changes or [])) or "- ìµœê·¼ ë³€ê²½ ì—†ìŒ ë³´ê³ "
    return (
        f"{DISCLAIMER}\n\n## ğŸ” ë¶ˆëŸ‰ ë¶„ì„\n"
        f"- ì½”ë“œ: {defect_code}\n- ì„¤ëª…: {defect_description}\n- ê³µì •: {process_step}\n"
        f"- ì¥ë¹„: {equipment_id or 'ë¯¸ì…ë ¥'} / ì›¨ì´í¼: {wafer_id or 'ë¯¸ì…ë ¥'}\n\n"
        f"### ì‚¬ìš©ì ì œì•ˆ ì›ì¸\n{causes}\n\n"
        f"### ì¼ë°˜ ì ê²€\n- ì¥ë¹„ ì•ŒëŒ/ë¡œê·¸\n- ìµœê·¼ PM/ìº˜ë¦¬ë¸Œë ˆì´ì…˜\n- ë ˆì‹œí”¼ ë³€ê²½ ì´ë ¥\n- ì†Œì¬/ì¼€ë¯¸ Lot\n- SPC/Lot í¸ì°¨\n\n"
        f"### ìµœê·¼ ë³€ê²½ ì‚¬í•­\n{changes}\n"
    )


def get_defect_history(defect_records: List[Dict[str, Any]], analysis_type: str = "trend") -> str:
    miss = _missing(["defect_records"], locals())
    if miss:
        return _err_missing(miss)
    if not defect_records:
        return f"{DISCLAIMER}\n\n## âš ï¸ ì…ë ¥ ì˜¤ë¥˜\në¶ˆëŸ‰ ì´ë ¥ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
    total = len(defect_records)
    wafer_sum = sum(r.get("wafer_count", 0) for r in defect_records)
    actions = [r.get("action_taken", "") for r in defect_records if r.get("action_taken")]
    unique_actions = list({a for a in actions})
    equip_counter: Dict[str, int] = {}
    for r in defect_records:
        eq = r.get("equipment_id", "ë¯¸ì…ë ¥")
        equip_counter[eq] = equip_counter.get(eq, 0) + 1
    top_equipment = sorted(equip_counter.items(), key=lambda x: x[1], reverse=True)
    top_equipment_text = "\n".join([f"- {eq}: {cnt}íšŒ" for eq, cnt in top_equipment[:3]]) or "- ë°ì´í„° ë¶€ì¡±"
    rows = "\n".join(
        f"| {r.get('date','-')} | {r.get('defect_type','-')} | {r.get('equipment_id','-')} | {r.get('wafer_count','-')} | {r.get('action_taken','-')} | {r.get('result','-')} |"
        for r in defect_records
    )
    return (
        f"{DISCLAIMER}\n\n## ğŸ“Š ë¶ˆëŸ‰ ì´ë ¥ ë¶„ì„ ({analysis_type})\n"
        f"- ì´ ì´ë ¥: {total}ê±´\n- ë¶ˆëŸ‰ ì›¨ì´í¼ í•©ê³„: {wafer_sum}ë§¤\n"
        f"- ì‚¬ìš©ëœ ì¡°ì¹˜: {', '.join(unique_actions) if unique_actions else 'ì¡°ì¹˜ ì •ë³´ ë¶€ì¡±'}\n\n"
        f"| ë‚ ì§œ | ë¶ˆëŸ‰ | ì¥ë¹„ | ì›¨ì´í¼ | ì¡°ì¹˜ | ê²°ê³¼ |\n|------|------|------|--------|------|------|\n{rows}\n\n"
        f"### íŒ¨í„´ ë°œê²¬\n- ì¥ë¹„ ì§‘ì¤‘ë„ ìƒìœ„\n{top_equipment_text}\n"
    )


def suggest_corrective_action(
    problem_description: str,
    affected_equipment: str,
    severity: str,
    current_status: str,
    available_resources: Optional[List[str]] = None,
    time_constraint: str = None,
) -> str:
    miss = _missing(["problem_description", "affected_equipment", "severity", "current_status"], locals())
    if miss:
        return _err_missing(miss)
    sev = severity.lower()
    immediate = {
        "critical": ["ì¦‰ì‹œ ì¥ë¹„ ì •ì§€", "ì˜í–¥ Lot ê²©ë¦¬", "ì „ë¬¸ ì—”ì§€ë‹ˆì–´ í˜¸ì¶œ"],
        "major": ["ê³µì • ì¼ì‹œ ì¤‘ì§€", "ì¡°ê±´ ì ê²€", "ì•ŒëŒ/ë¡œê·¸ ìˆ˜ì§‘"],
        "minor": ["ì¡°ê±´ ë¯¸ì„¸ ì¡°ì •", "ëª¨ë‹ˆí„°ë§ ê°•í™”"],
    }.get(sev, ["ìƒí™© í‰ê°€ í›„ ê²°ì •"])
    resources = "\n".join(f"- {r}" for r in (available_resources or ["ìì› ë¯¸ì…ë ¥"]))
    return (
        f"{DISCLAIMER}\n\n## ğŸ”§ ì‹œì • ì¡°ì¹˜ ì œì•ˆ\n"
        f"- ë¬¸ì œ: {problem_description}\n- ì¥ë¹„: {affected_equipment}\n- ì‹¬ê°ë„: {severity}\n- ìƒíƒœ: {current_status}\n- ì‹œê°„ ì œì•½: {time_constraint or 'ë¯¸ì…ë ¥'}\n\n"
        f"### ì¦‰ì‹œ ì¡°ì¹˜\n" + "\n".join(f"{i+1}. {v}" for i, v in enumerate(immediate)) + "\n\n"
        f"### í•„ìš” ìì›\n{resources}\n"
    )


def compare_to_baseline(
    baseline_recipe: Dict[str, Dict[str, Any]],
    current_recipe: Dict[str, float],
    recipe_name: str = None,
) -> str:
    miss = _missing(["baseline_recipe", "current_recipe"], locals())
    if miss:
        return _err_missing(miss)
    rows = []
    for p, meta in baseline_recipe.items():
        cur = current_recipe.get(p)
        status = "âœ…"
        min_v, max_v = meta.get("min"), meta.get("max")
        if cur is None:
            status = "âš ï¸ ë¯¸ì…ë ¥"
        elif (min_v is not None and cur < min_v) or (max_v is not None and cur > max_v):
            status = "âŒ ì´íƒˆ"
        rows.append(f"| {p} | {meta.get('value')} {meta.get('unit','')} | {cur} | {status} |")
    table = "\n".join(rows) if rows else "| - | - | - | - |"
    return (
        f"{DISCLAIMER}\n\n## ğŸ“ ê¸°ì¤€ ëŒ€ë¹„ ë¹„êµ\n- ë ˆì‹œí”¼: {recipe_name or 'ë¯¸ì…ë ¥'}\n\n"
        f"| íŒŒë¼ë¯¸í„° | ê¸°ì¤€ | í˜„ì¬ | ìƒíƒœ |\n|----------|------|------|------|\n{table}\n"
    )


def compare_two_recipes(
    recipe_a: Dict[str, float],
    recipe_b: Dict[str, float],
    recipe_a_name: str = "Recipe A",
    recipe_b_name: str = "Recipe B",
    tolerance: Optional[Dict[str, float]] = None,
) -> str:
    miss = _missing(["recipe_a", "recipe_b"], locals())
    if miss:
        return _err_missing(miss)
    rows = []
    all_params = set(recipe_a.keys()) | set(recipe_b.keys())
    for p in sorted(all_params):
        a, b = recipe_a.get(p), recipe_b.get(p)
        status = "âœ…"
        if tolerance and p in tolerance and a is not None and b is not None:
            diff_pct = ((b - a) / a * 100) if a else 0
            if abs(diff_pct) > tolerance[p]:
                status = "âŒ ì´ˆê³¼"
        rows.append(f"| {p} | {a} | {b} | {status} |")
    table = "\n".join(rows)
    return (
        f"{DISCLAIMER}\n\n## ğŸ”„ ë‘ ë ˆì‹œí”¼ ë¹„êµ\n- {recipe_a_name} vs {recipe_b_name}\n\n"
        f"| íŒŒë¼ë¯¸í„° | {recipe_a_name} | {recipe_b_name} | ìƒíƒœ |\n|----------|---------------|---------------|------|\n{table}\n"
    )


def validate_process_window(
    process_window: Dict[str, Dict[str, Any]],
    test_conditions: Dict[str, float],
    critical_params: Optional[List[str]] = None,
) -> str:
    miss = _missing(["process_window", "test_conditions"], locals())
    if miss:
        return _err_missing(miss)
    rows = []
    alerts = []
    for p, lim in process_window.items():
        val = test_conditions.get(p)
        min_v, max_v = lim.get("min"), lim.get("max")
        status = "âœ… PASS"
        if val is None or (min_v is not None and val < min_v) or (max_v is not None and val > max_v):
            status = "âŒ FAIL"
            if critical_params and p in critical_params:
                alerts.append(f"- ì¤‘ìš” {p}: {val} (ë²”ìœ„ {min_v}-{max_v})")
        rows.append(f"| {p} | {val} | {min_v}-{max_v} | {status} |")
    return (
        f"{DISCLAIMER}\n\n## âœ”ï¸ ê³µì • ìœˆë„ìš° ê²€ì¦\n"
        f"| íŒŒë¼ë¯¸í„° | ì…ë ¥ê°’ | ë²”ìœ„ | ê²°ê³¼ |\n|----------|--------|------|------|\n" + "\n".join(rows) + "\n\n"
        f"### ìœ„í—˜ íŒŒë¼ë¯¸í„°\n" + ("\n".join(alerts) if alerts else "- ì—†ìŒ")
    )


def analyze_metrics(
    metrics_data: Dict[str, float],
    targets: Dict[str, float],
    period: str = None,
    equipment_id: str = None,
) -> str:
    miss = _missing(["metrics_data", "targets"], locals())
    if miss:
        return _err_missing(miss)
    rows = []
    gaps = []
    for k, target in targets.items():
        cur = metrics_data.get(k)
        status = "âŒ ë¯¸ë‹¬" if cur is None or cur < target else "âœ… ë‹¬ì„±"
        rows.append(f"| {k} | {cur} | {target} | {status} |")
        if cur is None or cur < target:
            gaps.append(f"- {k}: {(cur - target) if cur is not None else 'N/A'}")
    return (
        f"{DISCLAIMER}\n\n## ğŸ“ˆ ë©”íŠ¸ë¦­ ë¶„ì„\n- ê¸°ê°„: {period or 'ë¯¸ì…ë ¥'} / ì¥ë¹„: {equipment_id or 'ì „ì²´'}\n\n"
        f"| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ | ìƒíƒœ |\n|------|------|------|------|\n" + "\n".join(rows)
        + "\n\n### ê°œì„  í•„ìš” í•­ëª©\n"
        + ("\n".join(gaps) if gaps else "- ëª¨ë“  KPI ë‹¬ì„±")
    )


def analyze_spc_data(
    data_points: List[float],
    spec_limits: Dict[str, float],
    control_limits: Optional[Dict[str, float]] = None,
    subgroup_size: int = 1,
    parameter_name: str = None,
    equipment_id: str = None,
) -> str:
    miss = _missing(["data_points", "spec_limits"], locals())
    if miss:
        return _err_missing(miss)
    if not data_points:
        return f"{DISCLAIMER}\n\n## âš ï¸ ì…ë ¥ ì˜¤ë¥˜\në°ì´í„° í¬ì¸íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."

    n = len(data_points)
    sample_warning = "âš ï¸ ISO 22514 ê¶Œì¥ ìµœì†Œ ìƒ˜í”Œ ìˆ˜(25ê°œ) ë¯¸ë‹¬. í•´ì„ ì£¼ì˜." if n < 25 else ""
    mean_val = statistics.mean(data_points)
    variance = statistics.pvariance(data_points) if n > 1 else 0.0
    std_dev = variance ** 0.5

    skewness = (
        sum((x - mean_val) ** 3 for x in data_points) / (n * (statistics.pvariance(data_points) ** 1.5))
        if n > 2 and std_dev > 0
        else 0.0
    )
    kurtosis = (
        sum((x - mean_val) ** 4 for x in data_points) / (n * (variance**2)) - 3
        if n > 3 and variance > 0
        else 0.0
    )
    is_normal = abs(skewness) < 1 and abs(kurtosis) < 2
    normality_warning = "" if is_normal else "âš ï¸ ì •ê·œì„± ë¯¸í¡ ê°€ëŠ¥. Cp/Cpk í•´ì„ ì£¼ì˜."

    A2_TABLE = {2: 1.880, 3: 1.023, 4: 0.729, 5: 0.577, 6: 0.483, 7: 0.419, 8: 0.373, 9: 0.337, 10: 0.308}
    if control_limits is None:
        if subgroup_size == 1:
            mrs = [abs(data_points[i] - data_points[i - 1]) for i in range(1, n)]
            mr_bar = statistics.mean(mrs) if mrs else 0.0
            d2 = 1.128
            sigma_within = mr_bar / d2 if d2 else std_dev
            ucl = mean_val + 3 * sigma_within
            lcl = mean_val - 3 * sigma_within
            cl = mean_val
            calc_method = "ì´ë™ë²”ìœ„ë²• (MR/d2)"
        else:
            subgroups = [data_points[i : i + subgroup_size] for i in range(0, n, subgroup_size)]
            subgroup_means = [statistics.mean(sg) for sg in subgroups if len(sg) == subgroup_size]
            subgroup_ranges = [(max(sg) - min(sg)) for sg in subgroups if len(sg) == subgroup_size]
            x_bar_bar = statistics.mean(subgroup_means) if subgroup_means else mean_val
            r_bar = statistics.mean(subgroup_ranges) if subgroup_ranges else 0.0
            A2 = A2_TABLE.get(subgroup_size, 0.577)
            ucl = x_bar_bar + A2 * r_bar
            lcl = x_bar_bar - A2 * r_bar
            cl = x_bar_bar
            sigma_within = std_dev
            calc_method = f"X-bar & R (A2={A2}, n={subgroup_size})"
    else:
        ucl = control_limits.get("ucl")
        lcl = control_limits.get("lcl")
        cl = control_limits.get("cl", mean_val)
        sigma_within = std_dev
        calc_method = "ì‚¬ìš©ì ì§€ì •"

    usl, lsl = spec_limits.get("usl"), spec_limits.get("lsl")
    sigma_overall = std_dev or sigma_within or 1e-9
    Cp = (usl - lsl) / (6 * sigma_within) if usl is not None and lsl is not None and sigma_within else None
    Pp = (usl - lsl) / (6 * sigma_overall) if usl is not None and lsl is not None and sigma_overall else None

    def _cpk(mean, usl, lsl, sigma):
        if (usl is None and lsl is None) or sigma == 0:
            return None
        if usl is not None and lsl is not None:
            return min((usl - mean) / (3 * sigma), (mean - lsl) / (3 * sigma))
        if usl is not None:
            return (usl - mean) / (3 * sigma)
        return (mean - lsl) / (3 * sigma)

    Cpk = _cpk(mean_val, usl, lsl, sigma_within)
    Ppk = _cpk(mean_val, usl, lsl, sigma_overall)
    violations = [x for x in data_points if (ucl is not None and x > ucl) or (lcl is not None and x < lcl)]
    violations_text = "\n".join(f"- {v:.3f}" for v in violations[:5]) if violations else "- ìœ„ë°˜ ì‚¬í•­ ì—†ìŒ âœ…"

    return f"""{DISCLAIMER}

## ğŸ“Š SPC ë¶„ì„ ê²°ê³¼
- íŒŒë¼ë¯¸í„°: {parameter_name or 'ë¯¸ì…ë ¥'} / ì¥ë¹„: {equipment_id or 'ë¯¸ì…ë ¥'}
- ê´€ë¦¬í•œê³„ ê³„ì‚°: {calc_method}
- ìƒ˜í”Œ ìˆ˜: {n}ê°œ {sample_warning}
- ì •ê·œì„±: {"ì •ìƒ" if is_normal else "ì£¼ì˜"} {normality_warning}

### ê¸°ë³¸ í†µê³„ëŸ‰
| í•­ëª© | ê°’ |
|------|-----|
| í‰ê·  (XÌ„) | {mean_val:.4f} |
| í‘œì¤€í¸ì°¨ (Ïƒ) | {std_dev:.4f} |
| ìµœëŒ€/ìµœì†Œ | {max(data_points):.4f} / {min(data_points):.4f} |

### ê´€ë¦¬í•œê³„
| í•­ëª© | ê°’ |
|------|-----|
| UCL | {ucl:.4f if ucl is not None else 'N/A'} |
| CL | {cl:.4f if cl is not None else 'N/A'} |
| LCL | {lcl:.4f if lcl is not None else 'N/A'} |

### ê³µì •ëŠ¥ë ¥ì§€ìˆ˜
| ì§€ìˆ˜ | ê°’ |
|------|-----|
| Cp / Pp | {Cp:.3f if Cp is not None else 'N/A'} / {Pp:.3f if Pp is not None else 'N/A'} |
| Cpk / Ppk | {Cpk:.3f if Cpk is not None else 'N/A'} / {Ppk:.3f if Ppk is not None else 'N/A'} |

### ê´€ë¦¬ í•œê³„ ì´íƒˆ
{violations_text}
"""


def predict_defect_risk(
    process_window: Dict[str, Dict[str, float]],
    current_conditions: Dict[str, float],
    severity_ratings: Optional[Dict[str, int]] = None,
    occurrence_ratings: Optional[Dict[str, int]] = None,
    detection_ratings: Optional[Dict[str, int]] = None,
    critical_params: Optional[List[str]] = None,
    historical_defect_correlation: Optional[Dict[str, str]] = None,
) -> str:
    miss = _missing(["process_window", "current_conditions"], locals())
    if miss:
        return _err_missing(miss)

    critical_params = critical_params or []
    severity_ratings = severity_ratings or {}
    occurrence_ratings = occurrence_ratings or {}
    detection_ratings = detection_ratings or {}
    historical_defect_correlation = historical_defect_correlation or {}

    def estimate_occurrence_from_margin(cur, min_v, max_v):
        rng = max_v - min_v
        if rng <= 0:
            return 5, "ë²”ìœ„ ì •ì˜ ë¶ˆëª…í™•"
        min_margin = min(max_v - cur, cur - min_v)
        margin_pct = (min_margin / (rng / 2)) * 100 if rng else 0
        if margin_pct <= 0:
            return 10, "ë²”ìœ„ ì´íƒˆ"
        if margin_pct < 10:
            return 8, "ë§ˆì§„ 10% ë¯¸ë§Œ"
        if margin_pct < 20:
            return 6, "ë§ˆì§„ 20% ë¯¸ë§Œ"
        if margin_pct < 30:
            return 5, "ë§ˆì§„ 30% ë¯¸ë§Œ"
        if margin_pct < 50:
            return 3, "ë§ˆì§„ 50% ë¯¸ë§Œ"
        return 2, "ë§ˆì§„ ì—¬ìœ "

    def action_priority(s, o, d, rpn):
        if s >= 9 and o >= 4:
            return "H"
        if s >= 5 and o >= 6:
            return "H"
        if s >= 5 and o >= 4 and d >= 6:
            return "M"
        if rpn >= 100:
            return "M"
        return "L"

    rows = []
    rpns = []
    for p, limits in process_window.items():
        cur = current_conditions.get(p)
        min_v, max_v = limits.get("min"), limits.get("max")
        if cur is None or min_v is None or max_v is None:
            continue
        S = severity_ratings.get(p, 5)
        if p in occurrence_ratings:
            O = occurrence_ratings[p]
            o_basis = "ì‚¬ìš©ì ì…ë ¥"
        else:
            O, o_basis = estimate_occurrence_from_margin(cur, min_v, max_v)
        D = detection_ratings.get(p, 5)
        RPN = S * O * D
        AP = action_priority(S, O, D, RPN)
        margin_pct = (min(max_v - cur, cur - min_v) / ((max_v - min_v) / 2)) * 100 if max_v != min_v else 0
        rows.append(
            f"| {p} | {cur} | {margin_pct:.1f}% | {S} | {O} | {D} | {RPN} | {AP} | {o_basis} | {historical_defect_correlation.get(p,'N/A')} |"
        )
        rpns.append(RPN)

    rows_text = "\n".join(rows) if rows else "| - | - | - | - | - | - | - | - | - | - |"
    max_rpn = max(rpns) if rpns else 0
    high_ap = " H " in rows_text
    if high_ap or max_rpn >= 200:
        overall = "ğŸ”´ ê³ ìœ„í—˜ - ì¦‰ì‹œ ì¡°ì¹˜"
    elif max_rpn >= 100:
        overall = "ğŸŸ¡ ì¤‘ìœ„í—˜ - ê³„íš ì¡°ì¹˜"
    else:
        overall = "ğŸŸ¢ ì €ìœ„í—˜ - ëª¨ë‹ˆí„°ë§"

    return f"""{DISCLAIMER}

## ğŸ” FMEA ê¸°ë°˜ ë¶ˆëŸ‰ ìœ„í—˜ë„ í‰ê°€
- ì ìš© ê¸°ì¤€: AIAG & VDA FMEA (ë‹¨ìˆœí™”)
- ì¤‘ìš” íŒŒë¼ë¯¸í„°: {', '.join(critical_params) if critical_params else 'ë¯¸ì…ë ¥'}

### ì¢…í•© ìœ„í—˜ë„
{overall}
- ìµœëŒ€ RPN: {max_rpn}

### íŒŒë¼ë¯¸í„°ë³„ FMEA í…Œì´ë¸”
| íŒŒë¼ë¯¸í„° | í˜„ì¬ê°’ | ë§ˆì§„ | S | O | D | RPN | AP | O ê·¼ê±° | ê³¼ê±° ìƒê´€ |
|----------|--------|------|---|---|---|-----|----|--------|-----------|
{rows_text}
"""


def optimize_recipe_direction(
    current_recipe: Dict[str, float],
    current_performance: Dict[str, float],
    target_performance: Dict[str, float],
    param_sensitivity: Optional[Dict[str, str]] = None,
    constraints: Optional[Dict[str, Dict[str, float]]] = None,
) -> str:
    miss = _missing(["current_recipe", "current_performance", "target_performance"], locals())
    if miss:
        return _err_missing(miss)
    param_sensitivity = param_sensitivity or {}
    constraints = constraints or {}
    perf_gaps = [(k, target - current_performance.get(k, 0)) for k, target in target_performance.items()]
    perf_text = "\n".join([f"- {k}: ëª©í‘œ ëŒ€ë¹„ {gap:+.2f}" for k, gap in perf_gaps]) or "- ë°ì´í„° ë¶€ì¡±"
    adjustments = []
    for p, _ in current_recipe.items():
        sens = param_sensitivity.get(p, "MEDIUM")
        cons = constraints.get(p, {})
        min_c, max_c = cons.get("min"), cons.get("max")
        direction = "ìƒí–¥" if any(gap > 0 for _, gap in perf_gaps) else "í•˜í–¥/ìµœì í™”"
        adjustments.append(f"- {p}: {direction} (ë¯¼ê°ë„ {sens}, ì œì•½ {min_c}-{max_c})")
    return (
        f"{DISCLAIMER}\n\n## âš™ï¸ ë ˆì‹œí”¼ ìµœì í™” ë°©í–¥\n"
        f"### ì„±ê³¼ ê°­ ë¶„ì„\n{perf_text}\n\n"
        f"### ì¡°ì • ê¶Œì¥ íŒŒë¼ë¯¸í„°\n" + "\n".join(adjustments or ["- ì…ë ¥ëœ íŒŒë¼ë¯¸í„° ì—†ìŒ"])
    )


def simulate_parameter_change(
    current_state: Dict[str, Any],
    proposed_changes: Dict[str, float],
    impact_rules: List[Dict[str, Any]],
    process_window: Optional[Dict[str, Dict[str, float]]] = None,
) -> str:
    miss = _missing(["current_state", "proposed_changes", "impact_rules"], locals())
    if miss:
        return _err_missing(miss)
    before_recipe = current_state.get("recipe", {})
    before_perf = current_state.get("performance", {})
    after_recipe = {**before_recipe, **proposed_changes}
    predicted_perf = before_perf.copy()
    for rule in impact_rules:
        impacts = rule.get("impact", {})
        for metric, delta in impacts.items():
            predicted_perf[metric] = predicted_perf.get(metric, 0) + delta
    window_alerts = []
    if process_window:
        for p, val in after_recipe.items():
            limits = process_window.get(p, {})
            min_v, max_v = limits.get("min"), limits.get("max")
            if min_v is not None and val < min_v:
                window_alerts.append(f"- {p}: {val} < {min_v}")
            if max_v is not None and val > max_v:
                window_alerts.append(f"- {p}: {val} > {max_v}")
    recipe_table = "\n".join([f"| {k} | {before_recipe.get(k,'-')} | {after_recipe.get(k,'-')} |" for k in after_recipe.keys()])
    perf_table = "\n".join([f"| {k} | {before_perf.get(k,'-')} | {predicted_perf.get(k,'-')} |" for k in predicted_perf.keys()])
    risk_text = "- ë²”ìœ„ ì´ˆê³¼ ì—†ìŒ" if not window_alerts else "ë²”ìœ„ ì´ˆê³¼:\n" + "\n".join(window_alerts)
    return (
        f"{DISCLAIMER}\n\n## ğŸ§ª íŒŒë¼ë¯¸í„° ë³€ê²½ ì‹œë®¬ë ˆì´ì…˜\n"
        f"### ë ˆì‹œí”¼ ë³€ê²½ ì „/í›„\n| íŒŒë¼ë¯¸í„° | Before | After |\n|----------|--------|-------|\n{recipe_table}\n\n"
        f"### ì˜ˆìƒ ì„±ê³¼ ë³€í™”\n| ì§€í‘œ | Before | After |\n|------|--------|-------|\n{perf_table}\n\n"
        f"### ë¦¬ìŠ¤í¬ í‰ê°€\n{risk_text}\n\n"
        f"### âš ï¸ ëª¨ë¸ í•œê³„\n"
        f"- ì‚¬ìš©ì ì •ì˜ ì˜í–¥ ê·œì¹™ì„ ì„ í˜• ê°€ì‚° ì ìš©\n"
        f"- ë¬¼ë¦¬/í™”í•™ ëª¨ë¸ ë° ë¹„ì„ í˜• íš¨ê³¼ ë¯¸í¬í•¨\n"
    )


def calculate_yield_impact(
    baseline_yield: float,
    parameter_changes: List[Dict[str, Any]],
    interaction_effects: Optional[List[Dict[str, Any]]] = None,
    confidence_level: float = 0.95,
    model_type: str = "linear",
) -> str:
    miss = _missing(["baseline_yield", "parameter_changes"], locals())
    if miss:
        return _err_missing(miss)
    linear_effects = []
    total_linear = 0.0
    for change in parameter_changes:
        delta = (change.get("to") - change.get("from")) if change.get("to") is not None and change.get("from") is not None else 0
        sens = change.get("yield_sensitivity", 0)
        effect = delta * sens
        total_linear += effect
        linear_effects.append(
            {"param": change.get("param"), "from": change.get("from"), "to": change.get("to"), "delta": delta, "sens": sens, "effect": effect}
        )
    interaction_total = sum(i.get("effect", 0) for i in (interaction_effects or []))
    predicted_yield = baseline_yield + total_linear + interaction_total
    total_effect = abs(total_linear) + abs(interaction_total)
    uncertainty = total_effect * 0.1 if total_effect > 0 else 0.1
    z = 1.96 if confidence_level >= 0.95 else 2.576
    ci_lower = predicted_yield - z * uncertainty
    ci_upper = predicted_yield + z * uncertainty
    linear_rows = "\n".join(
        f"| {e['param']} | {e['from']} â†’ {e['to']} | {e['delta']:+.2f} | {e['sens']:.4f} | {e['effect']:+.3f}% |"
        for e in linear_effects
    )
    inter_rows = (
        "\n".join([f"| {' Ã— '.join(i.get('params', []))} | {i.get('effect', 0):+.3f}% |" for i in (interaction_effects or [])])
        if interaction_effects
        else "| (ì—†ìŒ) | - |"
    )
    return f"""{DISCLAIMER}

## ğŸ“ˆ ìˆ˜ìœ¨ ì˜í–¥ ë¶„ì„ (DOE ê¸°ë°˜ ë‹¨ìˆœ ì˜ˆì¸¡)
- ëª¨ë¸: {model_type}
- ì‹ ë¢°ìˆ˜ì¤€: {confidence_level*100:.0f}%

### ê²°ê³¼
| í•­ëª© | ê°’ |
|------|-----|
| ê¸°ì¤€ ìˆ˜ìœ¨ | {baseline_yield:.2f}% |
| ì„ í˜• íš¨ê³¼ í•©ê³„ | {total_linear:+.3f}% |
| ìƒí˜¸ì‘ìš© í•©ê³„ | {interaction_total:+.3f}% |
| ì˜ˆì¸¡ ìˆ˜ìœ¨ | **{predicted_yield:.2f}%** |
| ì‹ ë¢°êµ¬ê°„ | [{ci_lower:.2f}%, {ci_upper:.2f}%] |

### ì„ í˜• íš¨ê³¼
| íŒŒë¼ë¯¸í„° | ë³€ê²½ | Î” | ë¯¼ê°ë„ | ì˜í–¥ |
|----------|------|---|--------|------|
{linear_rows}

### ìƒí˜¸ì‘ìš© íš¨ê³¼
| íŒŒë¼ë¯¸í„° ì¡°í•© | ì˜í–¥ |
|---------------|------|
{inter_rows}
"""


def analyze_equipment_comparison(
    equipment_data: List[Dict[str, Any]],
    weights: Optional[Dict[str, float]] = None,
    benchmark: Optional[Dict[str, float]] = None,
    normalization_method: str = "min-max",
) -> str:
    miss = _missing(["equipment_data"], locals())
    if miss:
        return _err_missing(miss)

    all_metrics = set()
    for eq in equipment_data:
        all_metrics.update(eq.get("metrics", {}).keys())
    if not all_metrics:
        return f"{DISCLAIMER}\n\n## âš ï¸ ì…ë ¥ ì˜¤ë¥˜\në©”íŠ¸ë¦­ì´ ì—†ìŠµë‹ˆë‹¤."

    if weights is None:
        weights = {m: 1 / len(all_metrics) for m in all_metrics}
    wsum = sum(weights.values()) or 1.0
    weight_warning = ""
    if abs(wsum - 1.0) > 0.01:
        weights = {k: v / wsum for k, v in weights.items()}
        weight_warning = f"âš ï¸ ê°€ì¤‘ì¹˜ í•©ê³„ {wsum:.2f} â†’ ì •ê·œí™” ì ìš©"

    higher_is_better = {"yield": True, "cpk": True, "uptime": True, "throughput": True, "mtbf": True, "defect_rate": False, "mttr": False}

    def norm_minmax(vals, higher=True):
        mn, mx = min(vals), max(vals)
        if mx == mn:
            return [0.5] * len(vals)
        return [((v - mn) / (mx - mn)) if higher else ((mx - v) / (mx - mn)) for v in vals]

    normalized = []
    for eq in equipment_data:
        norm_metrics = {}
        for m in all_metrics:
            vals = [e.get("metrics", {}).get(m, 0) for e in equipment_data]
            higher = higher_is_better.get(m, True)
            norm_vals = norm_minmax(vals, higher)
            norm_metrics[m] = norm_vals[equipment_data.index(eq)]
        score = sum(norm_metrics.get(m, 0) * weights.get(m, 0) for m in all_metrics) * 100
        normalized.append({"equipment_id": eq.get("equipment_id", "?"), "orig": eq.get("metrics", {}), "score": score})

    normalized.sort(key=lambda x: x["score"], reverse=True)
    for i, eq in enumerate(normalized):
        eq["rank"] = i + 1

    metric_headers = " | ".join(all_metrics)
    rows = "\n".join(
        f"| {eq['rank']} | {eq['equipment_id']} | {eq['score']:.1f} | " + " | ".join(str(eq["orig"].get(m, "N/A")) for m in all_metrics) + " |"
        for eq in normalized
    )

    bm_text = ""
    if benchmark:
        bm_rows = []
        for eq in normalized:
            checks = []
            for m, bm in benchmark.items():
                val = eq["orig"].get(m)
                if val is None:
                    checks.append("â“")
                    continue
                better = higher_is_better.get(m, True)
                ok = val >= bm if better else val <= bm
                checks.append("âœ…" if ok else "âŒ")
            bm_rows.append(f"| {eq['equipment_id']} | {' '.join(checks)} |")
        bm_text = "\n### ë²¤ì¹˜ë§ˆí¬ ë¹„êµ\n| ì¥ë¹„ | ì¶©ì¡± |\n|------|------|\n" + "\n".join(bm_rows)

    return f"""{DISCLAIMER}

## ğŸ­ ì¥ë¹„ ì„±ëŠ¥ ë¹„êµ (ê°€ì¤‘í•©)
- ì •ê·œí™”: {normalization_method.upper()}
- ê°€ì¤‘ì¹˜ í•©ê³„ ê²€ì¦: {weight_warning or 'OK'}

### ê°€ì¤‘ì¹˜
| ì§€í‘œ | ê°€ì¤‘ì¹˜ |
|------|--------|
{chr(10).join([f"| {m} | {w:.2%} |" for m, w in weights.items()])}

### ìˆœìœ„
| ìˆœìœ„ | ì¥ë¹„ | ì ìˆ˜ | {metric_headers} |
|------|------|------|{' | '.join(['---']*len(all_metrics))}|
{rows}
{bm_text}
"""


def generate_shift_report(
    production_summary: Dict[str, Any],
    equipment_status: List[Dict[str, Any]],
    quality_summary: Dict[str, Any],
    key_events: Optional[List[Dict[str, Any]]] = None,
    pending_actions: Optional[List[str]] = None,
    shift_info: Optional[Dict[str, str]] = None,
) -> str:
    miss = _missing(["production_summary", "equipment_status", "quality_summary"], locals())
    if miss:
        return _err_missing(miss)
    eq_rows = "\n".join(
        [f"| {e.get('equipment_id','-')} | {e.get('status','-')} | {e.get('issues','-')} |" for e in equipment_status]
    ) or "| - | - | - |"
    events_rows = "\n".join(
        [f"| {ev.get('time','-')} | {ev.get('event','-')} | {ev.get('action','-')} | {ev.get('status','-')} |" for ev in (key_events or [])]
    ) or "| - | - | - | - |"
    pending = "\n".join([f"- {p}" for p in (pending_actions or [])]) or "- ë¯¸ê²° ì—†ìŒ"
    return (
        f"{DISCLAIMER}\n\n## ğŸ“ êµëŒ€ ë¦¬í¬íŠ¸\n"
        f"- **êµëŒ€ ì •ë³´**: {shift_info.get('shift') if shift_info else 'ë¯¸ì…ë ¥'} / {shift_info.get('date') if shift_info else 'ë¯¸ì…ë ¥'}\n\n"
        f"### ìƒì‚° ìš”ì•½\n"
        f"- íˆ¬ì…: {production_summary.get('wafer_in','-')}\n"
        f"- ì™„ë£Œ: {production_summary.get('wafer_out','-')}\n"
        f"- ëª©í‘œ: {production_summary.get('target','-')}\n"
        f"- ìˆ˜ìœ¨: {production_summary.get('yield','-')}\n\n"
        f"### ì¥ë¹„ ìƒíƒœ\n| ì¥ë¹„ | ìƒíƒœ | ì´ìŠˆ |\n|------|------|------|\n{eq_rows}\n\n"
        f"### í’ˆì§ˆ ìš”ì•½\n"
        f"- ë¶ˆëŸ‰ ìˆ˜: {quality_summary.get('defect_count','-')}\n"
        f"- ì£¼ìš” ë¶ˆëŸ‰: {quality_summary.get('major_defects','-')}\n"
        f"- SPC ì•ŒëŒ: {quality_summary.get('spc_alerts','-')}\n\n"
        f"### ì£¼ìš” ì´ë²¤íŠ¸\n| ì‹œê°„ | ì´ë²¤íŠ¸ | ì¡°ì¹˜ | ìƒíƒœ |\n|------|--------|------|------|\n{events_rows}\n\n"
        f"### ì¸ìˆ˜ì¸ê³„ í•„ìš” ì‚¬í•­\n{pending}\n"
    )


def analyze_trend(
    time_series_data: List[Dict[str, Any]],
    parameter_name: str,
    spec_limits: Optional[Dict[str, float]] = None,
    analysis_options: Optional[Dict[str, Any]] = None,
) -> str:
    miss = _missing(["time_series_data", "parameter_name"], locals())
    if miss:
        return _err_missing(miss)
    values = [d.get("value") for d in time_series_data if d.get("value") is not None]
    n = len(values)
    if n < 5:
        return f"{DISCLAIMER}\n\n## âš ï¸ ë°ì´í„° ë¶€ì¡±\në¶„ì„ì„ ìœ„í•´ ìµœì†Œ 5ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {n}ê°œ)"

    analysis_options = analysis_options or {}
    forecast_points = analysis_options.get("forecast_points", 0)
    mean_val = sum(values) / n
    variance = sum((x - mean_val) ** 2 for x in values) / (n - 1)
    std_dev = variance**0.5

    x = list(range(n))
    x_mean = sum(x) / n
    y_mean = mean_val
    denom = sum((xi - x_mean) ** 2 for xi in x)
    slope = sum((x[i] - x_mean) * (values[i] - y_mean) for i in range(n)) / denom if denom else 0
    intercept = y_mean - slope * x_mean
    ss_tot = sum((v - y_mean) ** 2 for v in values)
    ss_res = sum((values[i] - (slope * x[i] + intercept)) ** 2 for i in range(n))
    r_squared = 1 - (ss_res / ss_tot) if ss_tot else 0
    if n > 2 and denom > 0:
        mse = ss_res / (n - 2)
        se_slope = (mse / denom) ** 0.5 if denom else 0
        t_stat = slope / se_slope if se_slope else 0
        t_crit = 2.0 if n > 30 else 2.3
        trend_significant = abs(t_stat) > t_crit
    else:
        t_stat = 0
        trend_significant = False

    def mann_kendall(data):
        s = 0
        for i in range(len(data) - 1):
            for j in range(i + 1, len(data)):
                diff = data[j] - data[i]
                if diff > 0:
                    s += 1
                elif diff < 0:
                    s -= 1
        var_s = (n * (n - 1) * (2 * n + 5)) / 18
        if s > 0:
            z = (s - 1) / (var_s**0.5)
        elif s < 0:
            z = (s + 1) / (var_s**0.5)
        else:
            z = 0
        trend_txt = "ìƒìŠ¹ ì¶”ì„¸(ìœ ì˜)" if z > 1.96 else "í•˜ë½ ì¶”ì„¸(ìœ ì˜)" if z < -1.96 else "ì¶”ì„¸ ì—†ìŒ(ë¹„ìœ ì˜)"
        return {"S": s, "Z": z, "trend": trend_txt, "significant": abs(z) > 1.96}

    mk = mann_kendall(values)
    first_half = values[: n // 2]
    second_half = values[n // 2 :]
    shift_size = 0
    shift_status = "ì‹œí”„íŠ¸ ì—†ìŒ"
    if first_half and second_half and std_dev > 0:
        shift_size = (sum(second_half) / len(second_half) - sum(first_half) / len(first_half)) / std_dev
        if abs(shift_size) > 1.5:
            shift_status = "ìœ ì˜í•œ ì‹œí”„íŠ¸"
        elif abs(shift_size) > 1.0:
            shift_status = "ì‹œí”„íŠ¸ ì˜ì‹¬"

    forecast_text = ""
    if forecast_points > 0:
        forecasts = []
        for i in range(forecast_points):
            fx = n + i
            fy = slope * fx + intercept
            forecasts.append(f"| +{i+1} | {fy:.4f} |")
        forecast_text = "\n### ì˜ˆì¸¡ (ì„ í˜• ì™¸ì‚½)\n| ì‹œì  | ì˜ˆì¸¡ê°’ |\n|------|--------|\n" + "\n".join(forecasts) + "\n"

    if mk["significant"] and trend_significant:
        conclusion = "ğŸ”´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì¶”ì„¸"
        action = "ì›ì¸ íŒŒì•… ë° ì¡°ì¹˜"
    elif mk["significant"] or trend_significant:
        conclusion = "ğŸŸ¡ ì¶”ì„¸ ì˜ì‹¬"
        action = "ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘/ëª¨ë‹ˆí„°ë§"
    else:
        conclusion = "ğŸŸ¢ ìœ ì˜í•œ ì¶”ì„¸ ì—†ìŒ"
        action = "í˜„ìƒ ìœ ì§€"

    spec_txt = ""
    if spec_limits:
        usl, lsl = spec_limits.get("usl"), spec_limits.get("lsl")
        out = [v for v in values if (usl is not None and v > usl) or (lsl is not None and v < lsl)]
        spec_txt = f"- ìŠ¤í™ ì´íƒˆ: {len(out)}ê±´"

    return f"""{DISCLAIMER}

## ğŸ“ˆ ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„
- ëŒ€ìƒ: {parameter_name}
- ë°ì´í„° ìˆ˜: {n}ê°œ
{spec_txt}

### ê¸°ë³¸ í†µê³„ëŸ‰
| í•­ëª© | ê°’ |
|------|-----|
| í‰ê·  | {mean_val:.4f} |
| í‘œì¤€í¸ì°¨ | {std_dev:.4f} |
| ìµœëŒ€/ìµœì†Œ | {max(values):.4f} / {min(values):.4f} |

### ì„ í˜• íšŒê·€(OLS)
| í•­ëª© | ê°’ | í•´ì„ |
|------|-----|------|
| ê¸°ìš¸ê¸° | {slope:.6f} | {'ì–‘(ìƒìŠ¹)' if slope>0 else 'ìŒ(í•˜ë½)' if slope<0 else '0'} |
| RÂ² | {r_squared:.4f} | |
| t-í†µê³„ëŸ‰ | {t_stat:.3f} | ìœ ì˜ì„±: {"ìœ ì˜" if trend_significant else "ë¹„ìœ ì˜"} |

### Mann-Kendall
| S | Z | íŒì • |
|---|---|------|
| {mk['S']} | {mk['Z']:.3f} | {mk['trend']} |

### ì‹œí”„íŠ¸ íƒì§€
| í•­ëª© | ê°’ |
|------|-----|
| ì‹œí”„íŠ¸ í¬ê¸°(Ïƒ) | {shift_size:.2f} |
| íŒì • | {shift_status} |

### ì¢…í•© íŒì •
- ê²°ë¡ : {conclusion}
- ê¶Œì¥ ì¡°ì¹˜: {action}
{forecast_text}
"""


TOOLS = [
    {
        "name": "analyze_defect",
        "description": "ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ë¶ˆëŸ‰ ì›ì¸ ë¶„ì„",
        "inputSchema": {
            "type": "object",
            "properties": {
                "defect_code": {"type": "string"},
                "defect_description": {"type": "string"},
                "process_step": {"type": "string"},
                "equipment_id": {"type": "string"},
                "wafer_id": {"type": "string"},
                "known_causes": {"type": "array", "items": {"type": "string"}},
                "recent_changes": {"type": "array", "items": {"type": "string"}},
            },
            "required": ["defect_code", "defect_description", "process_step"],
        },
    },
    {
        "name": "get_defect_history",
        "description": "ë¶ˆëŸ‰ ì´ë ¥ íŒ¨í„´ ë¶„ì„",
        "inputSchema": {
            "type": "object",
            "properties": {
                "defect_records": {"type": "array", "items": {"type": "object"}},
                "analysis_type": {"type": "string"},
            },
            "required": ["defect_records"],
        },
    },
    {
        "name": "suggest_corrective_action",
        "description": "ì‹œì • ì¡°ì¹˜ ê°€ì´ë“œ",
        "inputSchema": {
            "type": "object",
            "properties": {
                "problem_description": {"type": "string"},
                "affected_equipment": {"type": "string"},
                "severity": {"type": "string"},
                "current_status": {"type": "string"},
                "available_resources": {"type": "array", "items": {"type": "string"}},
                "time_constraint": {"type": "string"},
            },
            "required": ["problem_description", "affected_equipment", "severity", "current_status"],
        },
    },
    {
        "name": "compare_to_baseline",
        "description": "ê¸°ì¤€ ë ˆì‹œí”¼ ëŒ€ë¹„ ë¹„êµ",
        "inputSchema": {
            "type": "object",
            "properties": {
                "baseline_recipe": {"type": "object"},
                "current_recipe": {"type": "object"},
                "recipe_name": {"type": "string"},
            },
            "required": ["baseline_recipe", "current_recipe"],
        },
    },
    {
        "name": "compare_two_recipes",
        "description": "ë‘ ë ˆì‹œí”¼ ë¹„êµ",
        "inputSchema": {
            "type": "object",
            "properties": {
                "recipe_a": {"type": "object"},
                "recipe_b": {"type": "object"},
                "recipe_a_name": {"type": "string"},
                "recipe_b_name": {"type": "string"},
                "tolerance": {"type": "object"},
            },
            "required": ["recipe_a", "recipe_b"],
        },
    },
    {
        "name": "validate_process_window",
        "description": "ê³µì • ìœˆë„ìš° ê²€ì¦",
        "inputSchema": {
            "type": "object",
            "properties": {
                "process_window": {"type": "object"},
                "test_conditions": {"type": "object"},
                "critical_params": {"type": "array", "items": {"type": "string"}},
            },
            "required": ["process_window", "test_conditions"],
        },
    },
    {
        "name": "analyze_metrics",
        "description": "ë©”íŠ¸ë¦­ ëª©í‘œ ëŒ€ë¹„ ë¶„ì„",
        "inputSchema": {
            "type": "object",
            "properties": {
                "metrics_data": {"type": "object"},
                "targets": {"type": "object"},
                "period": {"type": "string"},
                "equipment_id": {"type": "string"},
            },
            "required": ["metrics_data", "targets"],
        },
    },
    {
        "name": "analyze_spc_data",
        "description": "ISO/AIAG ê¸°ë°˜ SPC ë°ì´í„° ë¶„ì„(ë‹¨ìˆœí™”)",
        "inputSchema": {
            "type": "object",
            "properties": {
                "data_points": {"type": "array", "items": {"type": "number"}},
                "spec_limits": {"type": "object"},
                "control_limits": {"type": "object"},
                "subgroup_size": {"type": "integer"},
                "parameter_name": {"type": "string"},
                "equipment_id": {"type": "string"},
            },
            "required": ["data_points", "spec_limits"],
        },
    },
    {
        "name": "predict_defect_risk",
        "description": "FMEA ê¸°ë°˜ ë¶ˆëŸ‰ ìœ„í—˜ë„ ì˜ˆì¸¡(ë‹¨ìˆœí™”)",
        "inputSchema": {
            "type": "object",
            "properties": {
                "process_window": {"type": "object"},
                "current_conditions": {"type": "object"},
                "severity_ratings": {"type": "object"},
                "occurrence_ratings": {"type": "object"},
                "detection_ratings": {"type": "object"},
                "critical_params": {"type": "array", "items": {"type": "string"}},
                "historical_defect_correlation": {"type": "object"},
            },
            "required": ["process_window", "current_conditions"],
        },
    },
    {
        "name": "optimize_recipe_direction",
        "description": "ë ˆì‹œí”¼ ìµœì í™” ë°©í–¥ ì œì•ˆ",
        "inputSchema": {
            "type": "object",
            "properties": {
                "current_recipe": {"type": "object"},
                "current_performance": {"type": "object"},
                "target_performance": {"type": "object"},
                "param_sensitivity": {"type": "object"},
                "constraints": {"type": "object"},
            },
            "required": ["current_recipe", "current_performance", "target_performance"],
        },
    },
    {
        "name": "simulate_parameter_change",
        "description": "íŒŒë¼ë¯¸í„° ë³€ê²½ ì‹œë®¬ë ˆì´ì…˜",
        "inputSchema": {
            "type": "object",
            "properties": {
                "current_state": {"type": "object"},
                "proposed_changes": {"type": "object"},
                "impact_rules": {"type": "array", "items": {"type": "object"}},
                "process_window": {"type": "object"},
            },
            "required": ["current_state", "proposed_changes", "impact_rules"],
        },
    },
    {
        "name": "calculate_yield_impact",
        "description": "DOE ê¸°ë°˜ ìˆ˜ìœ¨ ì˜í–¥ ê³„ì‚°(ë‹¨ìˆœí™”)",
        "inputSchema": {
            "type": "object",
            "properties": {
                "baseline_yield": {"type": "number"},
                "parameter_changes": {"type": "array", "items": {"type": "object"}},
                "interaction_effects": {"type": "array", "items": {"type": "object"}},
                "confidence_level": {"type": "number"},
                "model_type": {"type": "string"},
            },
            "required": ["baseline_yield", "parameter_changes"],
        },
    },
    {
        "name": "analyze_equipment_comparison",
        "description": "ì¥ë¹„ ë¹„êµ ë¶„ì„(ì •ê·œí™”+ê°€ì¤‘í•©)",
        "inputSchema": {
            "type": "object",
            "properties": {
                "equipment_data": {"type": "array", "items": {"type": "object"}},
                "weights": {"type": "object"},
                "benchmark": {"type": "object"},
                "normalization_method": {"type": "string"},
            },
            "required": ["equipment_data"],
        },
    },
    {
        "name": "generate_shift_report",
        "description": "êµëŒ€ ë¦¬í¬íŠ¸ ìƒì„±",
        "inputSchema": {
            "type": "object",
            "properties": {
                "production_summary": {"type": "object"},
                "equipment_status": {"type": "array", "items": {"type": "object"}},
                "quality_summary": {"type": "object"},
                "key_events": {"type": "array", "items": {"type": "object"}},
                "pending_actions": {"type": "array", "items": {"type": "string"}},
                "shift_info": {"type": "object"},
            },
            "required": ["production_summary", "equipment_status", "quality_summary"],
        },
    },
    {
        "name": "analyze_trend",
        "description": "íŠ¸ë Œë“œ ë¶„ì„(OLS+MK+Shift)",
        "inputSchema": {
            "type": "object",
            "properties": {
                "time_series_data": {"type": "array", "items": {"type": "object"}},
                "parameter_name": {"type": "string"},
                "spec_limits": {"type": "object"},
                "analysis_options": {"type": "object"},
            },
            "required": ["time_series_data", "parameter_name"],
        },
    },
]

TOOL_HANDLERS = {
    "analyze_defect": analyze_defect,
    "get_defect_history": get_defect_history,
    "suggest_corrective_action": suggest_corrective_action,
    "compare_to_baseline": compare_to_baseline,
    "compare_two_recipes": compare_two_recipes,
    "validate_process_window": validate_process_window,
    "analyze_metrics": analyze_metrics,
    "analyze_spc_data": analyze_spc_data,
    "predict_defect_risk": predict_defect_risk,
    "optimize_recipe_direction": optimize_recipe_direction,
    "simulate_parameter_change": simulate_parameter_change,
    "calculate_yield_impact": calculate_yield_impact,
    "analyze_equipment_comparison": analyze_equipment_comparison,
    "generate_shift_report": generate_shift_report,
    "analyze_trend": analyze_trend,
}


@app.get("/")
async def root():
    return {"service": "SemiProcess MCP", "spec": "2026-01-14", "health": "/health", "mcp": "/mcp", "tools_count": len(TOOLS)}


@app.get("/health")
async def health():
    return {"status": "healthy", "service": "SemiProcess MCP", "version": "2.0.0"}


@app.post("/mcp")
async def mcp_endpoint(request: Request):
    try:
        body = await request.json()
        method = body.get("method", "")
        params = body.get("params", {})
        request_id = body.get("id", 1)

        if method == "initialize":
            return JSONResponse(
                {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "protocolVersion": "2026-01-14",
                        "capabilities": {"tools": {}},
                        "serverInfo": {"name": "SemiProcess MCP", "version": "2.0.0"},
                    },
                }
            )
        if method == "notifications/initialized":
            return JSONResponse({"jsonrpc": "2.0", "id": request_id, "result": {}})
        if method == "tools/list":
            return JSONResponse({"jsonrpc": "2.0", "id": request_id, "result": {"tools": TOOLS}})
        if method == "tools/call":
            tool_name = params.get("name", "")
            arguments = params.get("arguments", {})
            handler = TOOL_HANDLERS.get(tool_name)
            if not handler:
                return JSONResponse(
                    {"jsonrpc": "2.0", "id": request_id, "error": {"code": -32601, "message": f"Unknown tool: {tool_name}"}}
                )
            try:
                result = handler(**arguments)
                return JSONResponse(
                    {"jsonrpc": "2.0", "id": request_id, "result": {"content": [{"type": "text", "text": result}]}}
                )
            except TypeError as e:
                return JSONResponse(
                    {"jsonrpc": "2.0", "id": request_id, "error": {"code": -32602, "message": f"Invalid parameters: {e}"}}
                )
            except Exception as e:
                return JSONResponse(
                    {"jsonrpc": "2.0", "id": request_id, "error": {"code": -32603, "message": f"Tool execution error: {e}"}}
                )
        return JSONResponse({"jsonrpc": "2.0", "id": request_id, "error": {"code": -32601, "message": f"Method not found: {method}"}})
    except Exception as e:
        return JSONResponse({"jsonrpc": "2.0", "id": 1, "error": {"code": -32700, "message": f"Parse error: {e}"}}, status_code=400)


@app.get("/favicon.ico")
async def favicon():
    return Response(status_code=204)
